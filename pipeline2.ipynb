{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import parse  \n",
    "from models import *\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "args = parse.get_args()\n",
    "\n",
    "class DataManager:\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "        ])\n",
    "        self.full_dataset = None\n",
    "        self.forget_dataset = None\n",
    "        self.retain_dataset = None\n",
    "        self.forget_loader = None\n",
    "        self.retain_loader = None\n",
    "        self.test_loader = None\n",
    "        \n",
    "    def load_data(self):\n",
    "        # Set random seed for reproducibility\n",
    "        torch.manual_seed(self.args.seed)\n",
    "        random.seed(self.args.seed)\n",
    "        np.random.seed(self.args.seed)\n",
    "        \n",
    "        # Load CIFAR-10 dataset\n",
    "        train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=self.transform)\n",
    "        test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=self.transform)\n",
    "        \n",
    "        # Identify indices of the class to forget\n",
    "        forget_class = self.args.forget_class\n",
    "        forget_indices = [i for i, (_, label) in enumerate(train_dataset) if label == forget_class]\n",
    "        retain_indices = [i for i, (_, label) in enumerate(train_dataset) if label != forget_class]\n",
    "\n",
    "        # Compute dataset sizes\n",
    "        forget_size = len(forget_indices)\n",
    "        retain_size = len(retain_indices)\n",
    "\n",
    "        # Create subset datasets\n",
    "        self.forget_dataset = Subset(train_dataset, forget_indices)\n",
    "        self.retain_dataset = Subset(train_dataset, retain_indices)\n",
    "\n",
    "        # Create data loaders\n",
    "        self.forget_loader = DataLoader(\n",
    "            self.forget_dataset, \n",
    "            batch_size=self.args.unlearn_batch_size, \n",
    "            shuffle=True, \n",
    "            num_workers=4\n",
    "        )\n",
    "        \n",
    "        self.retain_loader = DataLoader(\n",
    "            self.retain_dataset, \n",
    "            batch_size=self.args.unlearn_batch_size, \n",
    "            shuffle=True, \n",
    "            num_workers=4\n",
    "        )\n",
    "        \n",
    "        self.test_loader = DataLoader(\n",
    "            test_dataset, \n",
    "            batch_size=self.args.unlearn_batch_size, \n",
    "            shuffle=False, \n",
    "            num_workers=4\n",
    "        )\n",
    "        \n",
    "        print(f\"Data loaded: {forget_size} samples to forget, {retain_size} samples to retain\")\n",
    "        return self.forget_loader, self.retain_loader, self.test_loader\n",
    "\n",
    "\n",
    "class PotionUnlearner:\n",
    "    def __init__(self, args, model):\n",
    "        self.args = args\n",
    "        self.model = model\n",
    "        self.device = torch.device(args.device)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.AdamW(\n",
    "            self.model.parameters(),\n",
    "            lr=args.unlearn_lr,\n",
    "            weight_decay=args.unlearn_weight_decay\n",
    "        )\n",
    "        \n",
    "    def compute_potion_loss(self, outputs, labels, forget=False):\n",
    "        \"\"\"\n",
    "        Compute the Potion loss.\n",
    "        For retain set: standard cross-entropy loss\n",
    "        For forget set: negative cross-entropy loss with lambda regularization\n",
    "        \"\"\"\n",
    "        standard_loss = self.criterion(outputs, labels)\n",
    "        \n",
    "        if forget:\n",
    "            # For forget set: negative CE loss with regularization\n",
    "            return -self.args.potion_lambda * standard_loss\n",
    "        else:\n",
    "            # For retain set: standard CE loss\n",
    "            return standard_loss\n",
    "    \n",
    "    def train_step(self, images, labels, forget=False):\n",
    "        \"\"\"Single training step with Potion loss\"\"\"\n",
    "        images, labels = images.to(self.device), labels.to(self.device)\n",
    "        \n",
    "        # Forward pass\n",
    "        self.optimizer.zero_grad()\n",
    "        outputs = self.model(images)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = self.compute_potion_loss(outputs, labels, forget=forget)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # Compute accuracy\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct = predicted.eq(labels).sum().item()\n",
    "        \n",
    "        return loss.item(), correct\n",
    "    \n",
    "    def evaluate(self, data_loader, desc=\"Evaluating\"):\n",
    "        \"\"\"Evaluate the model on the given data loader\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(data_loader, desc=desc, leave=False):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                \n",
    "                total_loss += loss.item() * images.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "        \n",
    "        avg_loss = total_loss / total_samples\n",
    "        accuracy = correct / total_samples\n",
    "        \n",
    "        return avg_loss, accuracy\n",
    "    \n",
    "    def unlearn(self, forget_loader, retain_loader):\n",
    "        \"\"\"\n",
    "        Perform unlearning using Potion method.\n",
    "        Alternates between forgetting and retaining batches.\n",
    "        \"\"\"\n",
    "        print(f\"Starting unlearning process for {self.args.unlearn_epochs} epochs\")\n",
    "        \n",
    "        for epoch in range(1, self.args.unlearn_epochs + 1):\n",
    "            self.model.train()\n",
    "            forget_loss_sum = 0\n",
    "            retain_loss_sum = 0\n",
    "            forget_correct = 0\n",
    "            retain_correct = 0\n",
    "            forget_samples = 0\n",
    "            retain_samples = 0\n",
    "            \n",
    "            # Use zip to iterate through both loaders, cycling through the shorter one\n",
    "            forget_iter = iter(forget_loader)\n",
    "            retain_iter = iter(retain_loader)\n",
    "            \n",
    "            # Determine the number of iterations (use the length of the forget_loader)\n",
    "            num_iterations = len(forget_loader)\n",
    "            \n",
    "            for _ in tqdm(range(num_iterations), desc=f\"Epoch {epoch}/{self.args.unlearn_epochs}\"):\n",
    "                # Get forget batch (with cycling)\n",
    "                try:\n",
    "                    forget_images, forget_labels = next(forget_iter)\n",
    "                except StopIteration:\n",
    "                    forget_iter = iter(forget_loader)\n",
    "                    forget_images, forget_labels = next(forget_iter)\n",
    "                \n",
    "                # Get retain batch (with cycling)\n",
    "                try:\n",
    "                    retain_images, retain_labels = next(retain_iter)\n",
    "                except StopIteration:\n",
    "                    retain_iter = iter(retain_loader)\n",
    "                    retain_images, retain_labels = next(retain_iter)\n",
    "                \n",
    "                # Process forget batch\n",
    "                forget_loss, forget_batch_correct = self.train_step(\n",
    "                    forget_images, forget_labels, forget=True\n",
    "                )\n",
    "                forget_loss_sum += forget_loss * forget_images.size(0)\n",
    "                forget_correct += forget_batch_correct\n",
    "                forget_samples += forget_images.size(0)\n",
    "                \n",
    "                # Process retain batch\n",
    "                retain_loss, retain_batch_correct = self.train_step(\n",
    "                    retain_images, retain_labels, forget=False\n",
    "                )\n",
    "                retain_loss_sum += retain_loss * retain_images.size(0)\n",
    "                retain_correct += retain_batch_correct\n",
    "                retain_samples += retain_images.size(0)\n",
    "            \n",
    "            # Calculate average loss and accuracy\n",
    "            avg_forget_loss = forget_loss_sum / forget_samples\n",
    "            avg_retain_loss = retain_loss_sum / retain_samples\n",
    "            forget_accuracy = forget_correct / forget_samples\n",
    "            retain_accuracy = retain_correct / retain_samples\n",
    "            \n",
    "            print(f\"Epoch {epoch} Results:\")\n",
    "            print(f\"  Forget Set - Loss: {avg_forget_loss:.4f}, Accuracy: {forget_accuracy:.4f}\")\n",
    "            print(f\"  Retain Set - Loss: {avg_retain_loss:.4f}, Accuracy: {retain_accuracy:.4f}\")\n",
    "            \n",
    "            # Optionally, evaluate on both sets separately\n",
    "            if epoch % 5 == 0 or epoch == self.args.unlearn_epochs:\n",
    "                forget_test_loss, forget_test_acc = self.evaluate(\n",
    "                    forget_loader, desc=\"Evaluating Forget Set\"\n",
    "                )\n",
    "                retain_test_loss, retain_test_acc = self.evaluate(\n",
    "                    retain_loader, desc=\"Evaluating Retain Set\"\n",
    "                )\n",
    "                print(f\"  Evaluation - Forget Acc: {forget_test_acc:.4f}, Retain Acc: {retain_test_acc:.4f}\")\n",
    "        \n",
    "        print(\"Unlearning completed\")\n",
    "        \n",
    "    def save_model(self, path):\n",
    "        \"\"\"Save the unlearned model\"\"\"\n",
    "        directory = os.path.dirname(path)\n",
    "        if directory and not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        torch.save(self.model.state_dict(), path)\n",
    "        print(f\"Unlearned model saved to {path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model = ResNet50(num_classes=10).to(device)\n",
    "    model.load_state_dict(torch.load(args.model_path, map_location=device))\n",
    "    print(\"Model loaded\")\n",
    "    \n",
    "    # Prepare datasets\n",
    "    data_manager = DataManager(args)\n",
    "    forget_loader, retain_loader, test_loader = data_manager.load_data()\n",
    "    \n",
    "    # Evaluate initial model performance\n",
    "    unlearner = PotionUnlearner(args, model)\n",
    "    \n",
    "    print(\"Initial model performance:\")\n",
    "    forget_loss, forget_acc = unlearner.evaluate(forget_loader, \"Evaluating Forget Set\")\n",
    "    retain_loss, retain_acc = unlearner.evaluate(retain_loader, \"Evaluating Retain Set\")\n",
    "    test_loss, test_acc = unlearner.evaluate(test_loader, \"Evaluating Test Set\")\n",
    "    \n",
    "    print(f\"  Forget Set - Loss: {forget_loss:.4f}, Accuracy: {forget_acc:.4f}\")\n",
    "    print(f\"  Retain Set - Loss: {retain_loss:.4f}, Accuracy: {retain_acc:.4f}\")\n",
    "    print(f\"  Test Set - Loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    # Apply Potion unlearning\n",
    "    unlearner.unlearn(forget_loader, retain_loader)\n",
    "    \n",
    "    # Evaluate unlearned model\n",
    "    print(\"Unlearned model performance:\")\n",
    "    forget_loss, forget_acc = unlearner.evaluate(forget_loader, \"Evaluating Forget Set\")\n",
    "    retain_loss, retain_acc = unlearner.evaluate(retain_loader, \"Evaluating Retain Set\")\n",
    "    test_loss, test_acc = unlearner.evaluate(test_loader, \"Evaluating Test Set\")\n",
    "    \n",
    "    print(f\"  Forget Set - Loss: {forget_loss:.4f}, Accuracy: {forget_acc:.4f}\")\n",
    "    print(f\"  Retain Set - Loss: {retain_loss:.4f}, Accuracy: {retain_acc:.4f}\")\n",
    "    print(f\"  Test Set - Loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    # Save the unlearned model\n",
    "    unlearner.save_model(args.output_path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
