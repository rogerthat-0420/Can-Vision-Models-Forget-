{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import parse  \n",
    "from models import *\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# args = parse.get_args()\n",
    "\n",
    "class DataManager:\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "        ])\n",
    "        self.full_dataset = None\n",
    "        self.forget_dataset = None\n",
    "        self.retain_dataset = None\n",
    "        self.forget_loader = None\n",
    "        self.retain_loader = None\n",
    "        self.test_loader = None\n",
    "        \n",
    "    def load_data(self):\n",
    "        # Set random seed for reproducibility\n",
    "        torch.manual_seed(self.args.seed)\n",
    "        random.seed(self.args.seed)\n",
    "        np.random.seed(self.args.seed)\n",
    "        \n",
    "        # Load CIFAR-10 dataset\n",
    "        train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=self.transform)\n",
    "        test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=self.transform)\n",
    "        \n",
    "        # Identify indices of the class to forget\n",
    "        forget_class = int(self.args.forget_class)\n",
    "\n",
    "        forget_indices = [i for i, (_, label) in enumerate(train_dataset) if label == forget_class]\n",
    "        retain_indices = [i for i, (_, label) in enumerate(train_dataset) if label != forget_class]\n",
    "\n",
    "        # Compute dataset sizes\n",
    "        forget_size = len(forget_indices)\n",
    "        retain_size = len(retain_indices)\n",
    "\n",
    "        # Create subset datasets\n",
    "        self.forget_dataset = Subset(train_dataset, forget_indices)\n",
    "        self.retain_dataset = Subset(train_dataset, retain_indices)\n",
    "\n",
    "        # Create data loaders\n",
    "        self.forget_loader = DataLoader(\n",
    "            self.forget_dataset, \n",
    "            batch_size=self.args.unlearn_batch_size, \n",
    "            shuffle=True, \n",
    "            num_workers=4\n",
    "        )\n",
    "        \n",
    "        self.retain_loader = DataLoader(\n",
    "            self.retain_dataset, \n",
    "            batch_size=self.args.unlearn_batch_size, \n",
    "            shuffle=True, \n",
    "            num_workers=4\n",
    "        )\n",
    "        \n",
    "        self.test_loader = DataLoader(\n",
    "            test_dataset, \n",
    "            batch_size=self.args.unlearn_batch_size, \n",
    "            shuffle=False, \n",
    "            num_workers=4\n",
    "        )\n",
    "        \n",
    "        print(f\"Data loaded: {forget_size} samples to forget, {retain_size} samples to retain\")\n",
    "        return self.forget_loader, self.retain_loader, self.test_loader\n",
    "\n",
    "\n",
    "class PotionUnlearner:\n",
    "    def __init__(self, args, model):\n",
    "        self.args = args\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.AdamW(\n",
    "            self.model.parameters(),\n",
    "            lr=args.unlearn_lr,\n",
    "            weight_decay=args.unlearn_weight_decay\n",
    "        )\n",
    "        \n",
    "    def compute_potion_loss(self, outputs, labels, forget=False):\n",
    "        \"\"\"\n",
    "        Compute the Potion loss.\n",
    "        For retain set: standard cross-entropy loss\n",
    "        For forget set: negative cross-entropy loss with lambda regularization\n",
    "        \"\"\"\n",
    "        standard_loss = self.criterion(outputs, labels)\n",
    "        \n",
    "        if forget:\n",
    "            # For forget set: negative CE loss with regularization\n",
    "            return -self.args.potion_lambda * standard_loss\n",
    "        else:\n",
    "            # For retain set: standard CE loss\n",
    "            return standard_loss\n",
    "    \n",
    "    def train_step(self, images, labels, forget=False):\n",
    "        \"\"\"Single training step with Potion loss\"\"\"\n",
    "        images, labels = images.to(self.device), labels.to(self.device)\n",
    "        \n",
    "        # Forward pass\n",
    "        self.optimizer.zero_grad()\n",
    "        outputs = self.model(images)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = self.compute_potion_loss(outputs, labels, forget=forget)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # Compute accuracy\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct = predicted.eq(labels).sum().item()\n",
    "        \n",
    "        return loss.item(), correct\n",
    "    \n",
    "    def evaluate(self, data_loader, desc=\"Evaluating\"):\n",
    "        \"\"\"Evaluate the model on the given data loader\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(data_loader, desc=desc, leave=False):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                \n",
    "                total_loss += loss.item() * images.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "        \n",
    "        avg_loss = total_loss / total_samples\n",
    "        accuracy = correct / total_samples\n",
    "        \n",
    "        return avg_loss, accuracy\n",
    "    \n",
    "    def unlearn(self, forget_loader, retain_loader):\n",
    "        \"\"\"\n",
    "        Perform unlearning using Potion method.\n",
    "        Alternates between forgetting and retaining batches.\n",
    "        \"\"\"\n",
    "        print(f\"Starting unlearning process for {self.args.unlearn_epochs} epochs\")\n",
    "        \n",
    "        for epoch in range(1, self.args.unlearn_epochs + 1):\n",
    "            self.model.train()\n",
    "            forget_loss_sum = 0\n",
    "            retain_loss_sum = 0\n",
    "            forget_correct = 0\n",
    "            retain_correct = 0\n",
    "            forget_samples = 0\n",
    "            retain_samples = 0\n",
    "            \n",
    "            # Use zip to iterate through both loaders, cycling through the shorter one\n",
    "            forget_iter = iter(forget_loader)\n",
    "            retain_iter = iter(retain_loader)\n",
    "            \n",
    "            # Determine the number of iterations (use the length of the forget_loader)\n",
    "            num_iterations = len(forget_loader)\n",
    "            \n",
    "            for _ in tqdm(range(num_iterations), desc=f\"Epoch {epoch}/{self.args.unlearn_epochs}\"):\n",
    "                # Get forget batch (with cycling)\n",
    "                try:\n",
    "                    forget_images, forget_labels = next(forget_iter)\n",
    "                except StopIteration:\n",
    "                    forget_iter = iter(forget_loader)\n",
    "                    forget_images, forget_labels = next(forget_iter)\n",
    "                \n",
    "                # Get retain batch (with cycling)\n",
    "                try:\n",
    "                    retain_images, retain_labels = next(retain_iter)\n",
    "                except StopIteration:\n",
    "                    retain_iter = iter(retain_loader)\n",
    "                    retain_images, retain_labels = next(retain_iter)\n",
    "                \n",
    "                # Process forget batch\n",
    "                forget_loss, forget_batch_correct = self.train_step(\n",
    "                    forget_images, forget_labels, forget=True\n",
    "                )\n",
    "                forget_loss_sum += forget_loss * forget_images.size(0)\n",
    "                forget_correct += forget_batch_correct\n",
    "                forget_samples += forget_images.size(0)\n",
    "                \n",
    "                # Process retain batch\n",
    "                retain_loss, retain_batch_correct = self.train_step(\n",
    "                    retain_images, retain_labels, forget=False\n",
    "                )\n",
    "                retain_loss_sum += retain_loss * retain_images.size(0)\n",
    "                retain_correct += retain_batch_correct\n",
    "                retain_samples += retain_images.size(0)\n",
    "            \n",
    "            # Calculate average loss and accuracy\n",
    "            avg_forget_loss = forget_loss_sum / forget_samples\n",
    "            avg_retain_loss = retain_loss_sum / retain_samples\n",
    "            forget_accuracy = forget_correct / forget_samples\n",
    "            retain_accuracy = retain_correct / retain_samples\n",
    "            \n",
    "            print(f\"Epoch {epoch} Results:\")\n",
    "            print(f\"  Forget Set - Loss: {avg_forget_loss:.4f}, Accuracy: {forget_accuracy:.4f}\")\n",
    "            print(f\"  Retain Set - Loss: {avg_retain_loss:.4f}, Accuracy: {retain_accuracy:.4f}\")\n",
    "            \n",
    "            # Optionally, evaluate on both sets separately\n",
    "            if epoch % 5 == 0 or epoch == self.args.unlearn_epochs:\n",
    "                forget_test_loss, forget_test_acc = self.evaluate(\n",
    "                    forget_loader, desc=\"Evaluating Forget Set\"\n",
    "                )\n",
    "                retain_test_loss, retain_test_acc = self.evaluate(\n",
    "                    retain_loader, desc=\"Evaluating Retain Set\"\n",
    "                )\n",
    "                print(f\"  Evaluation - Forget Acc: {forget_test_acc:.4f}, Retain Acc: {retain_test_acc:.4f}\")\n",
    "        \n",
    "        print(\"Unlearning completed\")\n",
    "        \n",
    "    def save_model(self, path):\n",
    "        \"\"\"Save the unlearned model\"\"\"\n",
    "        directory = os.path.dirname(path)\n",
    "        if directory and not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        torch.save(self.model.state_dict(), path)\n",
    "        print(f\"Unlearned model saved to {path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import argparse\n",
    "\n",
    "args = argparse.Namespace(\n",
    "    model_path=\"models/resnet50_cifar10.pth\",\n",
    "    unlearn_batch_size=8,\n",
    "    unlearn_lr=0.0001,\n",
    "    unlearn_weight_decay=0.0001,\n",
    "    potion_lambda=0.1,\n",
    "    unlearn_epochs=10,\n",
    "    seed=42,\n",
    "    output_path=\"unlearned_models/resnet50_cifar10.pth\",\n",
    "    forget_class=\"0\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = ResNet50(num_classes=10).to(device)\n",
    "model.load_state_dict(torch.load(args.model_path, map_location=device))\n",
    "print(\"Model loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.shape =  torch.Size([3, 224, 224])\n",
      "b =  6\n",
      "len(forget_indices) =  5000\n",
      "Data loaded: 5000 samples to forget, 45000 samples to retain\n"
     ]
    }
   ],
   "source": [
    "# Prepare datasets\n",
    "data_manager = DataManager(args)\n",
    "forget_loader, retain_loader, test_loader = data_manager.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial model performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Forget Set - Loss: 0.3600, Accuracy: 0.8686\n",
      "  Retain Set - Loss: 0.7842, Accuracy: 0.7321\n",
      "  Test Set - Loss: 1.0941, Accuracy: 0.6797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Evaluate initial model performance\n",
    "unlearner = PotionUnlearner(args, model)\n",
    "\n",
    "print(\"Initial model performance:\")\n",
    "forget_loss, forget_acc = unlearner.evaluate(forget_loader, \"Evaluating Forget Set\")\n",
    "retain_loss, retain_acc = unlearner.evaluate(retain_loader, \"Evaluating Retain Set\")\n",
    "test_loss, test_acc = unlearner.evaluate(test_loader, \"Evaluating Test Set\")\n",
    "\n",
    "print(f\"  Forget Set - Loss: {forget_loss:.4f}, Accuracy: {forget_acc:.4f}\")\n",
    "print(f\"  Retain Set - Loss: {retain_loss:.4f}, Accuracy: {retain_acc:.4f}\")\n",
    "print(f\"  Test Set - Loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Potion unlearning\n",
    "unlearner.unlearn(forget_loader, retain_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting unlearning process for 10 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 625/625 [01:02<00:00, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Results:\n",
      "  Forget Set - Loss: -0.4892, Accuracy: 0.1648\n",
      "  Retain Set - Loss: 0.6674, Accuracy: 0.7726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/10: 100%|██████████| 625/625 [01:01<00:00, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Results:\n",
      "  Forget Set - Loss: -0.6485, Accuracy: 0.0800\n",
      "  Retain Set - Loss: 0.6722, Accuracy: 0.7750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/10: 100%|██████████| 625/625 [01:02<00:00, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Results:\n",
      "  Forget Set - Loss: -0.8006, Accuracy: 0.0402\n",
      "  Retain Set - Loss: 0.5844, Accuracy: 0.8044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/10: 100%|██████████| 625/625 [01:01<00:00, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Results:\n",
      "  Forget Set - Loss: -0.9583, Accuracy: 0.0134\n",
      "  Retain Set - Loss: 0.6043, Accuracy: 0.7974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/10: 100%|██████████| 625/625 [01:02<00:00, 10.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Results:\n",
      "  Forget Set - Loss: -1.1397, Accuracy: 0.0056\n",
      "  Retain Set - Loss: 0.5750, Accuracy: 0.8080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluation - Forget Acc: 0.0496, Retain Acc: 0.8098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 625/625 [01:01<00:00, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Results:\n",
      "  Forget Set - Loss: -1.3381, Accuracy: 0.0010\n",
      "  Retain Set - Loss: 0.6192, Accuracy: 0.7980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/10: 100%|██████████| 625/625 [01:02<00:00, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Results:\n",
      "  Forget Set - Loss: -1.5618, Accuracy: 0.0000\n",
      "  Retain Set - Loss: 0.6163, Accuracy: 0.8052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/10: 100%|██████████| 625/625 [01:02<00:00, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Results:\n",
      "  Forget Set - Loss: -1.8152, Accuracy: 0.0000\n",
      "  Retain Set - Loss: 0.6362, Accuracy: 0.7970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/10: 100%|██████████| 625/625 [01:01<00:00, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Results:\n",
      "  Forget Set - Loss: -2.0972, Accuracy: 0.0000\n",
      "  Retain Set - Loss: 0.6815, Accuracy: 0.7784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/10: 100%|██████████| 625/625 [01:01<00:00, 10.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Results:\n",
      "  Forget Set - Loss: -2.4206, Accuracy: 0.0000\n",
      "  Retain Set - Loss: 0.6973, Accuracy: 0.7868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluation - Forget Acc: 0.0000, Retain Acc: 0.8386\n",
      "Unlearning completed\n",
      "Unlearned model performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Forget Set - Loss: 17.3091, Accuracy: 0.0000\n",
      "  Retain Set - Loss: 0.5177, Accuracy: 0.8386\n",
      "  Test Set - Loss: 2.7122, Accuracy: 0.6784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate unlearned model\n",
    "print(\"Unlearned model performance:\")\n",
    "forget_loss, forget_acc = unlearner.evaluate(forget_loader, \"Evaluating Forget Set\")\n",
    "retain_loss, retain_acc = unlearner.evaluate(retain_loader, \"Evaluating Retain Set\")\n",
    "test_loss, test_acc = unlearner.evaluate(test_loader, \"Evaluating Test Set\")\n",
    "\n",
    "print(f\"  Forget Set - Loss: {forget_loss:.4f}, Accuracy: {forget_acc:.4f}\")\n",
    "print(f\"  Retain Set - Loss: {retain_loss:.4f}, Accuracy: {retain_acc:.4f}\")\n",
    "print(f\"  Test Set - Loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unlearned model saved to unlearned_models/resnet50_cifar10.pth\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Save the unlearned model\n",
    "unlearner.save_model(args.output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# arr = [0 for _ in range(10)]\n",
    "# for i in range(len(train_dataset)):\n",
    "#     label = train_dataset[i][1]\n",
    "#     print(label)\n",
    "#     arr[label]+=1\n",
    "    \n",
    "# print(arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
